{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Lasso, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def kf_splitting(data, n_splits_):\n",
    "    kf = KFold(n_splits=n_splits_)\n",
    "    df_split = []\n",
    "    for name, group in data.groupby([\"Store\", \"Dept\"]):\n",
    "        group = group.reset_index(drop=True)\n",
    "        trains_x = []\n",
    "        trains_y = []\n",
    "        tests_x = []\n",
    "        tests_y = []\n",
    "        if group.shape[0] <= 5:\n",
    "            f = np.array(range(5))\n",
    "            np.random.shuffle(f)\n",
    "            group['fold'] = f[:group.shape[0]]\n",
    "            continue\n",
    "        fold = 0\n",
    "        for train_index, test_index in kf.split(group):\n",
    "            group.loc[test_index, 'fold'] = fold\n",
    "            fold += 1\n",
    "        df_split.append(group)\n",
    "    df_split = pd.concat(df_split).reset_index(drop=True)\n",
    "    return df_split\n",
    "\n",
    "def gridsearch_wrapper(model, grid, refit_score, skfold_count, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"\n",
    "        fits a GridSearchCV classifier using refit_score for optimization\n",
    "        prints classifier performance metrics\n",
    "        \"\"\"\n",
    "        model = model()\n",
    "        skf = KFold(n_splits=10)\n",
    "        # scoring=scorers,\n",
    "        grid_search = GridSearchCV(\n",
    "            model, param_grid, \n",
    "            refit=refit_score,\n",
    "            cv=skf, return_train_score=True, n_jobs=-1\n",
    "        )\n",
    "        grid_search.fit(X_train.values, y_train.values)\n",
    "\n",
    "        # make the predictions\n",
    "        y_pred = grid_search.predict(X_test.values)\n",
    "\n",
    "        print('Best params for {}'.format(refit_score))\n",
    "        print(grid_search.best_params_)\n",
    "\n",
    "        # confusion matrix on the test data.\n",
    "        print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format(\n",
    "            refit_score\n",
    "        ))\n",
    "        print(pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                     columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "        return grid_search, grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in\n",
    "df_featurespace = pd.read_parquet(\"output/01_featurespace.parquet\")\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model List\n",
    "model_list = [Lasso, LinearRegression, RandomForestRegressor, ExtraTreesRegressor, KNeighborsRegressor]\n",
    "n_splits_ = 4\n",
    "scorers = {\n",
    "    'mae': make_scorer(mean_absolute_error)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'RandomForestRegressor': {\n",
    "        'bootstrap': [True],\n",
    "        'max_features': ['auto'],\n",
    "        'max_leaf_nodes': [None],\n",
    "        'min_samples_leaf': [4, 8],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'n_estimators': [10, 35],\n",
    "        'n_jobs': [-1],\n",
    "        'warm_start': [False]\n",
    "    },\n",
    "    'ExtraTreesRegressor': {\n",
    "        'bootstrap': [True],\n",
    "        'criterion': ['mse'],\n",
    "        'max_features': ['auto'],\n",
    "        'max_leaf_nodes': [None],\n",
    "        'min_samples_leaf': [4, 8],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'n_estimators': [10, 35],\n",
    "        'n_jobs': [-1],\n",
    "        'oob_score': [False],\n",
    "        'random_state': [42],\n",
    "        'verbose': [0],\n",
    "        'warm_start': [False]\n",
    "    },\n",
    "    \"KNeighborsRegressor\": {\n",
    "        'n_neighbors': [10, 12, 15]\n",
    "    },\n",
    "    \"LinearRegression\": {\n",
    "        'normalize': [True],\n",
    "        'fit_intercept': [True]\n",
    "    },\n",
    "    \"Lasso\": {\n",
    "        \"alpha\": [0.1, 0.4, 0.6],\n",
    "        \"fit_intercept\": [True],\n",
    "        \"normalize\": [True],\n",
    "        \"selection\": ['random']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to train\n",
    "df_train.drop(labels=['IsHoliday'], axis=1, inplace=True)\n",
    "df_train_fs = pd.merge(\n",
    "    df_train,\n",
    "    df_featurespace,\n",
    "    how='left',\n",
    "    on=['Store', 'Date'],\n",
    "    validate='m:1'\n",
    ")\n",
    "\n",
    "# Merge to test\n",
    "df_test.drop(labels=['IsHoliday'], axis=1, inplace=True)\n",
    "df_test_fs = pd.merge(\n",
    "    df_test,\n",
    "    df_featurespace,\n",
    "    how='left',\n",
    "    on=['Store', 'Date'],\n",
    "    validate='m:1'\n",
    ")\n",
    "df_train_fs.drop(labels=['Date'], axis=1, inplace=True)\n",
    "df_test_fs.drop(labels=['Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store', 'Dept', 'Weekly_Sales', 'Temperature', 'Fuel_Price', 'CPI',\n",
       "       'Unemployment', 'IsHoliday', 'Type', 'Size', 'Month', 'isSpring',\n",
       "       'isSummer', 'isFall', 'isWinter', 'cpiUpperGroup', 'unemploymentAbove9',\n",
       "       'store_month_mean_temp', 'temp_diff_store_month_mean',\n",
       "       'store_temp_rlg_max', 'temperature_cv', 'upcoming_holiday',\n",
       "       'MarkDown1_null_ind', 'MarkDown1_zero_ind', 'MarkDown1_log',\n",
       "       'MarkDown2_null_ind', 'MarkDown2_zero_ind', 'MarkDown2_log',\n",
       "       'MarkDown3_null_ind', 'MarkDown3_zero_ind', 'MarkDown3_log',\n",
       "       'MarkDown4_null_ind', 'MarkDown4_zero_ind', 'MarkDown4_log',\n",
       "       'MarkDown5_null_ind', 'MarkDown5_zero_ind', 'MarkDown5_log'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_fs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store', 'Dept', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment',\n",
       "       'IsHoliday', 'Type', 'Size', 'Month', 'isSpring', 'isSummer', 'isFall',\n",
       "       'isWinter', 'cpiUpperGroup', 'unemploymentAbove9',\n",
       "       'store_month_mean_temp', 'temp_diff_store_month_mean',\n",
       "       'store_temp_rlg_max', 'temperature_cv', 'upcoming_holiday',\n",
       "       'MarkDown1_null_ind', 'MarkDown1_zero_ind', 'MarkDown1_log',\n",
       "       'MarkDown2_null_ind', 'MarkDown2_zero_ind', 'MarkDown2_log',\n",
       "       'MarkDown3_null_ind', 'MarkDown3_zero_ind', 'MarkDown3_log',\n",
       "       'MarkDown4_null_ind', 'MarkDown4_zero_ind', 'MarkDown4_log',\n",
       "       'MarkDown5_null_ind', 'MarkDown5_zero_ind', 'MarkDown5_log'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_fs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train\n",
    "df_split = kf_splitting(df_train_fs, n_splits_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'sklearn.linear_model.coordinate_descent.Lasso'>, <class 'sklearn.linear_model.base.LinearRegression'>, <class 'sklearn.ensemble.forest.RandomForestRegressor'>, <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, <class 'sklearn.neighbors.regression.KNeighborsRegressor'>]\n",
      "First Model :: Lasso\n",
      "{'alpha': [0.1, 0.4, 0.6], 'fit_intercept': [True], 'normalize': [True], 'selection': ['random']}\n",
      "<class 'sklearn.linear_model.coordinate_descent.Lasso'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 514, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 703, in fit\n    copy=X_copied, multi_output=True, y_numeric=True)\n  File \"/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 719, in check_X_y\n    estimator=estimator)\n  File \"/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 542, in check_array\n    allow_nan=force_all_finite == 'allow-nan')\n  File \"/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 56, in _assert_all_finite\n    raise ValueError(msg_err.format(type_err, X.dtype))\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-255-f74e968d2a14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                                         \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                         \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                                         y_test=y_test)\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-242-0ab8efc965bb>\u001b[0m in \u001b[0;36mgridsearch_wrapper\u001b[0;34m(model, grid, refit_score, skfold_count, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         )\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# make the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/team62_jupyter/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/team62_jupyter/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "error_cv = 0\n",
    "best_error = np.iinfo(np.int32).max\n",
    "print(model_list)\n",
    "for model_ in model_list:\n",
    "\n",
    "    # Get train / test split for GridSearch\n",
    "    test = df_train_fs.loc[:, 'Weekly_Sales'].astype(float)\n",
    "    train = df_train_fs.drop(labels=['Weekly_Sales'], axis=1, inplace=False)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, test, test_size=0.33, random_state=42)\n",
    "    \n",
    "    # Param Grid and Searcg\n",
    "    print(\"First Model :: {}\".format(str(model_.__name__)))\n",
    "    param_grid_ = param_grids[str(model_.__name__)]\n",
    "    print(param_grid_)\n",
    "    print(model_)\n",
    "    gs, gs_best_p_ = gridsearch_wrapper(model=model_, \n",
    "                                        grid=param_grid_, \n",
    "                                        refit_score='mae',\n",
    "                                        skfold_count=10,\n",
    "                                        X_train=X_train, \n",
    "                                        X_test=X_test, \n",
    "                                        y_train=y_train, \n",
    "                                        y_test=y_test)\n",
    "    results = pd.DataFrame(grid_search_clf.cv_results_)\n",
    "    \n",
    "    for fold in range(5):\n",
    "    \n",
    "        # Split to train and test\n",
    "        dataset_train = df_split.loc[df_split['fold'] != fold]\n",
    "        dataset_test = df_split.loc[df_split['fold'] == fold]\n",
    "        train_y = dataset_train['weeklySales']\n",
    "        train_x = dataset_train.drop(columns=['weeklySales', 'fold'])\n",
    "        test_y = dataset_test['weeklySales']\n",
    "        test_x = dataset_test.drop(columns=['weeklySales', 'fold'])\n",
    "        print(\" ---- ---- ---- \")\n",
    "        print(\"Dataset train and test shapes :: current iteration\")\n",
    "        print(dataset_train.shape, dataset_test.shape)\n",
    "    \n",
    "        # Train / Test Model\n",
    "        #predicted, model = train_and_predict(train_x, train_y, test_x)\n",
    "        model_.fit(train_x, train_y)\n",
    "        yhat = model_.predict(test_x)\n",
    "    \n",
    "        weights = test_x['isHoliday'].replace(True, 5).replace(False, 1)\n",
    "        error = mean_absolute_error(test_y, yhat, weights)\n",
    "        error_cv += error\n",
    "        print(fold, error)\n",
    "        if error < best_error:\n",
    "            print('Find best model')\n",
    "            best_error = error\n",
    "            best_model = model\n",
    "    error_cv /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
