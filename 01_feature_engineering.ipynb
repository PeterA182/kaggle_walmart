{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_data():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in Features View\n",
    "    df_ft = pd.read_csv(\"data/features.csv\")\n",
    "    pre_ = df_ft.shape[0]\n",
    "    df_ft.drop_duplicates(inplace=True)\n",
    "    assert df_ft.shape[0] == pre_\n",
    "    \n",
    "    # Read in Stores View\n",
    "    df_stores = pd.read_csv(\"data/stores.csv\")\n",
    "    pre_ = df_stores.shape[0]\n",
    "    df_stores.drop_duplicates(inplace=True)\n",
    "    assert df_stores.shape[0] == pre_\n",
    "    \n",
    "    # Combine Stores and Features\n",
    "    df_ft = pd.merge(\n",
    "        df_ft,\n",
    "        df_stores,\n",
    "        how='left',\n",
    "        on=['Store'],\n",
    "        validate='m:1'\n",
    "    )\n",
    "    del df_stores\n",
    "    gc.collect()\n",
    "    \n",
    "    return df_ft\n",
    "\n",
    "\n",
    "def read_in_train_test():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in Features View\n",
    "    train = pd.read_csv(\"data/train.csv\")\n",
    "    pre_ = train.shape[0]\n",
    "    train.drop_duplicates(inplace=True)\n",
    "    assert df_ft.shape[0] == pre_\n",
    "    \n",
    "    # Read in Stores View\n",
    "    test = pd.read_csv(\"data/test.csv\")\n",
    "    pre_ = test.shape[0]\n",
    "    test.drop_duplicates(inplace=True)\n",
    "    assert test.shape[0] == pre_\n",
    "    \n",
    "    return train, test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['features.csv', 'sampleSubmission.csv', 'stores.csv', 'test.csv', 'train.csv']\n",
      "output directories made...\n"
     ]
    }
   ],
   "source": [
    "# Fnames and Paths\n",
    "fnames = os.listdir(\"data/\")\n",
    "print(fnames)\n",
    "\n",
    "try:\n",
    "    os.makedirs(\"output/\")\n",
    "except:\n",
    "    pass\n",
    "print(\"output directories made...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurespace merged with store data...\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def add_season(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Date to Month\n",
    "    data['Date'] = pd.to_datetime(data.Date)\n",
    "    data['Month'] = data['Date'].dt.month.astype(int)\n",
    "    \n",
    "    # Season flags\n",
    "    data['isSpring'] = (data['Month'].isin([3, 4, 5])).astype(int)\n",
    "    data['isSummer'] = (data['Month'].isin([6, 7, 8])).astype(int)\n",
    "    data['isFall'] = (data['Month'].isin([9, 10, 11])).astype(int)\n",
    "    data['isWinter'] = (data['Month'].isin([12, 1, 2])).astype(int)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def add_cpi_cutoff(data):\n",
    "    \n",
    "    # Apply cutoff from EDA\n",
    "    data['cpiUpperGroup'] = (data['CPI'] >= 75).astype(int)\n",
    "    return data\n",
    "\n",
    "def add_unemployment_cutoff(data):\n",
    "    \n",
    "    # Apply cutoff from EDA\n",
    "    data['unemploymentAbove9'] = (data['Unemployment'] >= 9).astype(int)\n",
    "    return data\n",
    "\n",
    "def fill_cpi(data):\n",
    "    \n",
    "    # Get Type-specific CPI averages\n",
    "    avgs = {typ: data.loc[data.Type==typ, :]['CPI'].mean() for typ in set(data['Type'])}\n",
    "    data.loc[data.CPI.isnull(), 'CPI'] = data.Type.map(avgs)\n",
    "    assert sum(data.CPI.isnull()) == 0\n",
    "    return data\n",
    "\n",
    "def fill_unemployment_typemonth(data):\n",
    "    \n",
    "    assert 'unemploymentAbove9' in data.columns\n",
    "    \n",
    "    # Get Type-Month specific Unemployments averages\n",
    "    data['type_month'] = data.Type.astype(str)+\"_\"+data.Month.astype(str)\n",
    "    avgs = data.groupby(by=['Type', 'Month'],\n",
    "                       as_index=False).agg({'Unemployment': np.mean})\n",
    "    avgs['type_month'] = avgs.Type.astype(str)+\"_\"+avgs.Month.astype(str)\n",
    "    avgs = {tm: avgs.loc[avgs['type_month'] == tm, :]['Unemployment'].mean() for tm in set(avgs['type_month'])}\n",
    "    data.loc[data.Unemployment.isnull(), 'Unemployment'] = data.type_month.map(avgs)\n",
    "    data.drop(labels=['type_month'], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def holiday_flag_to_bool(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    data.loc[:, 'IsHoliday'] = data['IsHoliday'].astype(int)\n",
    "    return data\n",
    "\n",
    "def flag_pre_holiday(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort\n",
    "    data.sort_values(by=['Store', 'Month'], ascending=True, inplace=True)\n",
    "    data.loc[:, 'upcoming_holiday'] = (data.IsHoliday.shift(-1)==1).astype(int)\n",
    "    assert all(data.upcoming_holiday.notnull())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def temp_diff_from_store_month_mean(data):\n",
    "    \"\"\"\n",
    "    Difference from store,month average temperature\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get store,month mean reference table\n",
    "    aggr = data.groupby(\n",
    "        by=['Store', 'Month'], \n",
    "        as_index=False\n",
    "    ).agg({'Temperature': np.mean})\n",
    "    aggr.rename(columns={'Temperature': 'store_month_mean_temp'},\n",
    "               inplace=True)\n",
    "    \n",
    "    # Merge back\n",
    "    data = pd.merge(\n",
    "        data,\n",
    "        aggr,\n",
    "        how='left',\n",
    "        on=['Store', 'Month'],\n",
    "        validate='m:1'\n",
    "    )\n",
    "    \n",
    "    # Calculate Diff\n",
    "    print(sorted(list(data.columns)))\n",
    "    data.loc[:, 'temp_diff_store_month_mean'] = (\n",
    "        data.Temperature - data.store_month_mean_temp\n",
    "    )\n",
    "    assert all(data.temp_diff_store_month_mean.notnull())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def temp_diff_from_lagged_max(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Sort\n",
    "    data.sort_values(by=['Store', 'Date'],\n",
    "                     ascending=True,\n",
    "                     inplace=True)\n",
    "    \n",
    "    # Get rolling max\n",
    "    data['store_temp_rlg_max'] = \\\n",
    "        data.groupby('Store')['Temperature'].rolling(window=4).max().reset_index(drop=True)\n",
    "    \n",
    "    mthly_max = data.groupby(by=['Store', 'Month'],\n",
    "                             as_index=False).agg({'Temperature': 'max'})\n",
    "    mthly_max['pair'] = mthly_max.Store.astype(str)+\"_\"+mthly_max.Month.astype(str)\n",
    "    mthly_max = mthly_max.set_index('pair')['Temperature'].to_dict()\n",
    "    \n",
    "    # Backfill rolling max empty with Store Month max\n",
    "    data.loc[:, 'pair'] = data.Store.astype(str)+\"_\"+data.Month.astype(str)\n",
    "    data.loc[data['store_temp_rlg_max'].isnull(), 'store_temp_rlg_max'] = data.pair.map(mthly_max)\n",
    "    assert all(data.store_temp_rlg_max.notnull())\n",
    "    data.drop(labels=['pair'], axis=1, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def temp_cv_month(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # SD\n",
    "    data['temp_sigma'] = data.groupby(by=['Store', 'Month'])['Temperature'].std().reset_index(drop=True)\n",
    "    # Mean\n",
    "    data['temp_mean'] = data.groupby(by=['Store', 'Month'])['Temperature'].mean().reset_index(drop=True)\n",
    "    # Ratio\n",
    "    data['temperature_cv'] = (data.temp_sigma / data.temp_mean)\n",
    "    data['temperature_cv'].fillna(0, inplace=True)\n",
    "    assert all(data['temperature_cv'].notnull())\n",
    "    data.drop(labels=['temp_sigma', 'temp_mean'], axis=1, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def fill_markdowns(data):\n",
    "    \n",
    "    # Replace negatives with 0\n",
    "    for col in [x for x in data.columns if 'markdown' in x.lower()]:\n",
    "        df.loc[df[col]<0, col] = 0\n",
    "    \n",
    "    # Fill Markdowns with KMEANS group assigned means\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurespace merged with store data...\n"
     ]
    }
   ],
   "source": [
    "df_ft = read_in_data()\n",
    "print(\"Featurespace merged with store data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CPI', 'Date', 'Fuel_Price', 'IsHoliday', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'Month', 'Size', 'Store', 'Temperature', 'Type', 'Unemployment', 'cpiUpperGroup', 'isFall', 'isSpring', 'isSummer', 'isWinter', 'store_month_mean_temp', 'unemploymentAbove9']\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "df_ft = add_season(df_ft)\n",
    "df_ft = add_cpi_cutoff(df_ft)\n",
    "df_ft = holiday_flag_to_bool(df_ft)\n",
    "df_ft = add_unemployment_cutoff(df_ft)\n",
    "df_ft = fill_cpi(df_ft)\n",
    "df_ft = fill_unemployment_typemonth(df_ft)\n",
    "df_ft = temp_diff_from_store_month_mean(df_ft)\n",
    "df_ft = temp_diff_from_lagged_max(df_ft)\n",
    "df_ft = temp_cv_month(df_ft)\n",
    "df_ft = flag_pre_holiday(df_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store                         0.000000\n",
       "Date                          0.000000\n",
       "Temperature                   0.000000\n",
       "Fuel_Price                    0.000000\n",
       "MarkDown1                     0.507692\n",
       "MarkDown2                     0.643346\n",
       "MarkDown3                     0.558852\n",
       "MarkDown4                     0.577045\n",
       "MarkDown5                     0.505495\n",
       "CPI                           0.000000\n",
       "Unemployment                  0.000000\n",
       "IsHoliday                     0.000000\n",
       "Type                          0.000000\n",
       "Size                          0.000000\n",
       "Month                         0.000000\n",
       "isSpring                      0.000000\n",
       "isSummer                      0.000000\n",
       "isFall                        0.000000\n",
       "isWinter                      0.000000\n",
       "cpiUpperGroup                 0.000000\n",
       "unemploymentAbove9            0.000000\n",
       "store_month_mean_temp         0.000000\n",
       "temp_diff_store_month_mean    0.000000\n",
       "store_temp_rlg_max            0.000000\n",
       "temperature_cv                0.000000\n",
       "upcoming_holiday              0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ft.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7605\n",
       "1     585\n",
       "Name: IsHoliday, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
