{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_data():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in Features View\n",
    "    df_ft = pd.read_csv(\"data/features.csv\")\n",
    "    pre_ = df_ft.shape[0]\n",
    "    df_ft.drop_duplicates(inplace=True)\n",
    "    assert df_ft.shape[0] == pre_\n",
    "    \n",
    "    # Read in Stores View\n",
    "    df_stores = pd.read_csv(\"data/stores.csv\")\n",
    "    pre_ = df_stores.shape[0]\n",
    "    df_stores.drop_duplicates(inplace=True)\n",
    "    assert df_stores.shape[0] == pre_\n",
    "    \n",
    "    # Combine Stores and Features\n",
    "    df_ft = pd.merge(\n",
    "        df_ft,\n",
    "        df_stores,\n",
    "        how='left',\n",
    "        on=['Store'],\n",
    "        validate='m:1'\n",
    "    )\n",
    "    del df_stores\n",
    "    gc.collect()\n",
    "    \n",
    "    return df_ft\n",
    "\n",
    "\n",
    "def read_in_train_test():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in Features View\n",
    "    train = pd.read_csv(\"data/train.csv\")\n",
    "    pre_ = train.shape[0]\n",
    "    train.drop_duplicates(inplace=True)\n",
    "    assert df_ft.shape[0] == pre_\n",
    "    \n",
    "    # Read in Stores View\n",
    "    test = pd.read_csv(\"data/test.csv\")\n",
    "    pre_ = test.shape[0]\n",
    "    test.drop_duplicates(inplace=True)\n",
    "    assert test.shape[0] == pre_\n",
    "    \n",
    "    return train, test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['features.csv', 'sampleSubmission.csv', 'stores.csv', 'test.csv', 'train.csv']\n",
      "output directories made...\n"
     ]
    }
   ],
   "source": [
    "# Fnames and Paths\n",
    "fnames = os.listdir(\"data/\")\n",
    "print(fnames)\n",
    "\n",
    "try:\n",
    "    os.makedirs(\"output/\")\n",
    "except:\n",
    "    pass\n",
    "print(\"output directories made...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store        Date  Temperature  Fuel_Price  MarkDown1  MarkDown2  \\\n",
       "0      1  2010-02-05        42.31       2.572        NaN        NaN   \n",
       "1      1  2010-02-12        38.51       2.548        NaN        NaN   \n",
       "2      1  2010-02-19        39.93       2.514        NaN        NaN   \n",
       "3      1  2010-02-26        46.63       2.561        NaN        NaN   \n",
       "4      1  2010-03-05        46.50       2.625        NaN        NaN   \n",
       "\n",
       "   MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
       "0        NaN        NaN        NaN  211.096358         8.106      False  \n",
       "1        NaN        NaN        NaN  211.242170         8.106       True  \n",
       "2        NaN        NaN        NaN  211.289143         8.106      False  \n",
       "3        NaN        NaN        NaN  211.319643         8.106      False  \n",
       "4        NaN        NaN        NaN  211.350143         8.106      False  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(\"data/stores.csv\")\n",
    "#df.head()\n",
    "# df = pd.read_csv(\"data/train.csv\")\n",
    "# df.head()\n",
    "df = pd.read_csv(\"data/features.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def add_season(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Date to Month\n",
    "    data['Date'] = pd.to_datetime(data.Date)\n",
    "    data['Month'] = data['Date'].dt.month.astype(int)\n",
    "    \n",
    "    # Season flags\n",
    "    data['isSpring'] = (data['Month'].isin([3, 4, 5])).astype(int)\n",
    "    data['isSummer'] = (data['Month'].isin([6, 7, 8])).astype(int)\n",
    "    data['isFall'] = (data['Month'].isin([9, 10, 11])).astype(int)\n",
    "    data['isWinter'] = (data['Month'].isin([12, 1, 2])).astype(int)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def add_cpi_cutoff(data):\n",
    "    \n",
    "    # Apply cutoff from EDA\n",
    "    data['cpiUpperGroup'] = (data['CPI'] >= 75).astype(int)\n",
    "    return data\n",
    "\n",
    "def add_unemployment_cutoff(data):\n",
    "    \n",
    "    # Apply cutoff from EDA\n",
    "    data['unemploymentAbove9'] = (data['Unemployment'] >= 9).astype(int)\n",
    "    return data\n",
    "\n",
    "def fill_cpi(data):\n",
    "    \n",
    "    # Get Type-specific CPI averages\n",
    "    avgs = {typ: data.loc[data.Type==typ, :]['CPI'].mean() for typ in set(data['Type'])}\n",
    "    data.loc[data.CPI.isnull(), 'CPI'] = data.Type.map(avgs)\n",
    "    assert sum(data.CPI.isnull()) == 0\n",
    "    return data\n",
    "\n",
    "def fill_unemployment_typemonth(data):\n",
    "    \n",
    "    assert 'unemploymentAbove9' in data.columns\n",
    "    \n",
    "    # Get Type-Month specific Unemployments averages\n",
    "    data['type_month'] = data.Type.astype(str)+\"_\"+data.Month.astype(str)\n",
    "    avgs = data.groupby(by=['Type', 'Month'],\n",
    "                       as_index=False).agg({'Unemployment': np.mean})\n",
    "    avgs['type_month'] = avgs.Type.astype(str)+\"_\"+avgs.Month.astype(str)\n",
    "    avgs = {tm: avgs.loc[avgs['type_month'] == tm, :]['Unemployment'].mean() for tm in set(avgs['type_month'])}\n",
    "    data.loc[data.Unemployment.isnull(), 'Unemployment'] = data.type_month.map(avgs)\n",
    "    data.drop(labels=['type_month'], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def holiday_flag_to_bool(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    data.loc[:, 'IsHoliday'] = data['IsHoliday'].astype(int)\n",
    "    return data\n",
    "\n",
    "def flag_pre_holiday(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort\n",
    "    data.sort_values(by=['Store', 'Month'], ascending=True, inplace=True)\n",
    "    data.loc[:, 'upcoming_holiday'] = (data.IsHoliday.shift(-1)==1).astype(int)\n",
    "    assert all(data.upcoming_holiday.notnull())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def temp_diff_from_store_month_mean(data):\n",
    "    \"\"\"\n",
    "    Difference from store,month average temperature\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get store,month mean reference table\n",
    "    aggr = data.groupby(\n",
    "        by=['Store', 'Month'], \n",
    "        as_index=False\n",
    "    ).agg({'Temperature': np.mean})\n",
    "    aggr.rename(columns={'Temperature': 'store_month_mean_temp'},\n",
    "               inplace=True)\n",
    "    \n",
    "    # Merge back\n",
    "    data = pd.merge(\n",
    "        data,\n",
    "        aggr,\n",
    "        how='left',\n",
    "        on=['Store', 'Month'],\n",
    "        validate='m:1'\n",
    "    )\n",
    "    \n",
    "    # Calculate Diff\n",
    "    print(sorted(list(data.columns)))\n",
    "    data.loc[:, 'temp_diff_store_month_mean'] = (\n",
    "        data.Temperature - data.store_month_mean_temp\n",
    "    )\n",
    "    assert all(data.temp_diff_store_month_mean.notnull())\n",
    "    \n",
    "    return data\n",
    "\n",
    "def temp_diff_from_lagged_max(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Sort\n",
    "    data.sort_values(by=['Store', 'Date'],\n",
    "                     ascending=True,\n",
    "                     inplace=True)\n",
    "    \n",
    "    # Get rolling max\n",
    "    data['store_temp_rlg_max'] = \\\n",
    "        data.groupby('Store')['Temperature'].rolling(window=4).max().reset_index(drop=True)\n",
    "    \n",
    "    mthly_max = data.groupby(by=['Store', 'Month'],\n",
    "                             as_index=False).agg({'Temperature': 'max'})\n",
    "    mthly_max['pair'] = mthly_max.Store.astype(str)+\"_\"+mthly_max.Month.astype(str)\n",
    "    mthly_max = mthly_max.set_index('pair')['Temperature'].to_dict()\n",
    "    \n",
    "    # Backfill rolling max empty with Store Month max\n",
    "    data.loc[:, 'pair'] = data.Store.astype(str)+\"_\"+data.Month.astype(str)\n",
    "    data.loc[data['store_temp_rlg_max'].isnull(), 'store_temp_rlg_max'] = data.pair.map(mthly_max)\n",
    "    assert all(data.store_temp_rlg_max.notnull())\n",
    "    data.drop(labels=['pair'], axis=1, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def temp_cv_month(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # SD\n",
    "    data['temp_sigma'] = data.groupby(by=['Store', 'Month'])['Temperature'].std().reset_index(drop=True)\n",
    "    # Mean\n",
    "    data['temp_mean'] = data.groupby(by=['Store', 'Month'])['Temperature'].mean().reset_index(drop=True)\n",
    "    # Ratio\n",
    "    data['temperature_cv'] = (data.temp_sigma / data.temp_mean)\n",
    "    data['temperature_cv'].fillna(0, inplace=True)\n",
    "    assert all(data['temperature_cv'].notnull())\n",
    "    data.drop(labels=['temp_sigma', 'temp_mean'], axis=1, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def fill_log_markdowns(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    md_cols = [x for x in data.columns if 'markdown' in x.lower()]\n",
    "    \n",
    "    # Replace negatives with 0\n",
    "    for m in md_cols:\n",
    "        data.loc[data[m]<0, m] = 0\n",
    "        data.loc[:, '{}_null_ind'.format(m)] = (data[m].isnull().astype(int))\n",
    "        data[m].fillna(0, inplace=True)\n",
    "        data['{}_zero_ind'.format(m)] = (data[m] == 0).astype(int)\n",
    "        data['{}_log'.format(m)] = np.log(data[m])\n",
    "        \n",
    "    data.drop(labels=md_cols, axis=1, inplace=True)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def encode_store_types(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    store_type_labels = LabelEncoder()\n",
    "    store_type_labels.fit(data.Type)\n",
    "    data.loc[:, 'Type'] = store_type_labels.transform(data.Type).astype(int)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurespace merged with store data...\n",
      "Index(['Store', 'Date', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2',\n",
      "       'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment',\n",
      "       'IsHoliday', 'Type', 'Size'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_ft = read_in_data()\n",
    "print(\"Featurespace merged with store data...\")\n",
    "print(df_ft.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CPI', 'Date', 'Fuel_Price', 'IsHoliday', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'Month', 'Size', 'Store', 'Temperature', 'Type', 'Unemployment', 'cpiUpperGroup', 'isFall', 'isSpring', 'isSummer', 'isWinter', 'store_month_mean_temp', 'unemploymentAbove9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/team62_jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:153: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "df_ft = add_season(df_ft)\n",
    "df_ft = add_cpi_cutoff(df_ft)\n",
    "df_ft = holiday_flag_to_bool(df_ft)\n",
    "df_ft = add_unemployment_cutoff(df_ft)\n",
    "df_ft = fill_cpi(df_ft)\n",
    "df_ft = fill_unemployment_typemonth(df_ft)\n",
    "df_ft = temp_diff_from_store_month_mean(df_ft)\n",
    "df_ft = temp_diff_from_lagged_max(df_ft)\n",
    "df_ft = temp_cv_month(df_ft)\n",
    "df_ft = flag_pre_holiday(df_ft)\n",
    "df_ft = fill_log_markdowns(df_ft)\n",
    "df_ft = encode_store_types(df_ft)\n",
    "\n",
    "assert np.sum(df_ft.isnull().mean()) == 0\n",
    "df_ft.to_parquet(\"output/01_featurespace.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store                                  int64\n",
       "Date                          datetime64[ns]\n",
       "Temperature                          float64\n",
       "Fuel_Price                           float64\n",
       "CPI                                  float64\n",
       "Unemployment                         float64\n",
       "IsHoliday                              int64\n",
       "Type                                   int64\n",
       "Size                                   int64\n",
       "Month                                  int64\n",
       "isSpring                               int64\n",
       "isSummer                               int64\n",
       "isFall                                 int64\n",
       "isWinter                               int64\n",
       "cpiUpperGroup                          int64\n",
       "unemploymentAbove9                     int64\n",
       "store_month_mean_temp                float64\n",
       "temp_diff_store_month_mean           float64\n",
       "store_temp_rlg_max                   float64\n",
       "temperature_cv                       float64\n",
       "upcoming_holiday                       int64\n",
       "MarkDown1_null_ind                     int64\n",
       "MarkDown1_zero_ind                     int64\n",
       "MarkDown1_log                        float64\n",
       "MarkDown2_null_ind                     int64\n",
       "MarkDown2_zero_ind                     int64\n",
       "MarkDown2_log                        float64\n",
       "MarkDown3_null_ind                     int64\n",
       "MarkDown3_zero_ind                     int64\n",
       "MarkDown3_log                        float64\n",
       "MarkDown4_null_ind                     int64\n",
       "MarkDown4_zero_ind                     int64\n",
       "MarkDown4_log                        float64\n",
       "MarkDown5_null_ind                     int64\n",
       "MarkDown5_zero_ind                     int64\n",
       "MarkDown5_log                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ft.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
